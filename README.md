# Audio Suite Pro

<div align="center">

![Audio Suite Pro Banner](assets/banner.svg)

**A powerful, web-based audio transcription and text processing suite powered by OpenAI**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Demo](https://img.shields.io/badge/Demo-Live-green.svg)](https://chrisdcg.github.io/Lokal_neu/)
[![Version](https://img.shields.io/badge/Version-1.0.0-blue.svg)](VERSION.md)
[![CI](https://github.com/ChrisDCG/Lokal_neu/workflows/CI/badge.svg)](https://github.com/ChrisDCG/Lokal_neu/actions)

[Demo](https://chrisdcg.github.io/Lokal_neu/) â€¢ [Documentation](#documentation) â€¢ [Contributing](CONTRIBUTING.md) â€¢ [Roadmap](ROADMAP.md) â€¢ [API Guide](docs/API_INTEGRATION.md)

</div>

## ğŸ¯ Overview

Audio Suite Pro is a sophisticated web application that transforms audio recordings into transcribed text using OpenAI's Whisper AI model. It offers advanced features for audio processing, text refinement, translation, and history management - all within a beautiful, responsive interface.

### âœ¨ Key Features

- **ğŸ¤ Real-time Audio Recording** - Record directly in your browser with visual audio feedback
- **ğŸ“ File Upload Support** - Process existing audio/video files in multiple formats
- **ğŸ§  AI-Powered Transcription** - Leverage OpenAI Whisper for accurate speech-to-text conversion
- **ğŸ‘¥ Speaker Recognition** - Identify and label different speakers in conversations
- **ğŸ”„ Text Refinement** - AI-powered text improvement and grammar correction
- **ğŸŒ Multi-language Translation** - Translate transcripts to 14+ languages
- **ğŸ“ Smart Summarization** - Generate concise summaries of long transcripts
- **ğŸ—£ï¸ Text-to-Speech** - Convert text back to speech with browser TTS
- **ğŸ“š Custom Vocabulary** - Add specialized terms for better transcription accuracy
- **ğŸ•’ Time Tracking** - Specialized mode for dictation and time logging
- **ğŸ“‹ History Management** - Search, filter, and manage transcription history
- **ğŸ¨ Dual Themes** - Light and dark mode support
- **ğŸŒ Internationalization** - Support for German, English, French, Spanish, Chinese, and Arabic

## ğŸš€ Quick Start

### Prerequisites

- Modern web browser (Chrome, Firefox, Safari, Edge)
- OpenAI API key ([Get one here](https://platform.openai.com/api-keys))
- Microphone access for recording (optional)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/ChrisDCG/Lokal_neu.git
   cd Lokal_neu
   ```

2. **Serve the application**
   ```bash
   # Option 1: Using Python
   python -m http.server 8000
   
   # Option 2: Using Node.js
   npx serve .
   
   # Option 3: Using Live Server (VS Code extension)
   # Open index.html and click "Go Live"
   ```

3. **Open in browser**
   Navigate to `http://localhost:8000` in your web browser

4. **Configure OpenAI API**
   - Click the settings gear icon
   - Enter your OpenAI API key
   - Click "Save"

### Usage

1. **Record Audio**: Click "Start Recording" or press F5 to begin recording
2. **Upload File**: Use "Upload File" button to process existing audio/video files
3. **Configure Options**: 
   - Set source language (or use auto-detect)
   - Add context/prompts for better accuracy
   - Enable speaker recognition if needed
   - Choose automatic text refinement
4. **Process**: Audio is automatically transcribed using OpenAI Whisper
5. **Enhance**: Use AI tools to refine, summarize, or translate your text
6. **Export**: Copy, email, or download your results as .txt files

## ğŸ“ Project Structure

```
Lokal_neu/
â”œâ”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ js/
â”‚   â”‚   â””â”€â”€ script.js            # Main application logic
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css            # Styling and themes
â”‚   â””â”€â”€ index.html               # Main HTML file
â”œâ”€â”€ assets/                       # Static assets
â”‚   â”œâ”€â”€ images/                  # Images and icons
â”‚   â”œâ”€â”€ logo.svg                 # Application logo
â”‚   â””â”€â”€ banner.png               # Project banner
â”œâ”€â”€ .github/                      # GitHub configuration
â”‚   â”œâ”€â”€ workflows/               # CI/CD workflows
â”‚   â”œâ”€â”€ ISSUE_TEMPLATE/          # Issue templates
â”‚   â””â”€â”€ pull_request_template.md # PR template
â”œâ”€â”€ tests/                        # Test files
â”‚   â”œâ”€â”€ unit/                    # Unit tests
â”‚   â””â”€â”€ integration/             # Integration tests
â”œâ”€â”€ docs/                         # Documentation
â”œâ”€â”€ CONTRIBUTING.md               # Contribution guidelines
â”œâ”€â”€ ROADMAP.md                   # Project roadmap
â”œâ”€â”€ LICENSE                      # MIT License
â”œâ”€â”€ package.json                 # Dependencies and scripts
â””â”€â”€ README.md                    # This file
```

## ğŸ› ï¸ Development

### Local Development Setup

1. **Install dependencies**
   ```bash
   npm install
   ```

2. **Start development server**
   ```bash
   npm run dev
   ```

3. **Run linting**
   ```bash
   npm run lint
   npm run lint:css
   ```

4. **Run tests**
   ```bash
   npm test
   ```

### Configuration

The application stores configuration in browser localStorage:
- OpenAI API key (encrypted)
- UI theme preference
- Language settings
- Transcription history
- Custom vocabulary

### API Integration

Audio Suite Pro integrates with OpenAI's API endpoints:
- **Whisper API** (`/v1/audio/transcriptions`) - Speech-to-text
- **Chat Completions API** (`/v1/chat/completions`) - Text processing, refinement, and translation

## ğŸ”§ Configuration Options

### Audio Settings
- **Language**: Set source audio language or use auto-detection
- **Temperature**: Control transcription creativity (0-1)
- **Context/Prompt**: Provide context for better accuracy
- **Speaker Recognition**: Enable diarization for multi-speaker audio

### Processing Options
- **Continuous Transcription**: Append new transcriptions to existing text
- **Auto-Refinement**: Automatically improve transcribed text
- **Time Tracking Mode**: Specialized formatting for time logging
- **Custom Vocabulary**: Add domain-specific terms

## ğŸŒ Supported Languages

### Interface Languages
- ğŸ‡©ğŸ‡ª German (Deutsch)
- ğŸ‡ºğŸ‡¸ English
- ğŸ‡«ğŸ‡· French (FranÃ§ais)
- ğŸ‡ªğŸ‡¸ Spanish (EspaÃ±ol)
- ğŸ‡¨ğŸ‡³ Chinese (ä¸­æ–‡)
- ğŸ‡¸ğŸ‡¦ Arabic (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)

### Transcription Languages
Supports all languages supported by OpenAI Whisper, including:
- English, German, Spanish, French, Italian, Portuguese
- Dutch, Polish, Swedish, Russian, Chinese, Japanese
- Korean, Arabic, and many more

### Translation Languages
- English (US), German, French, Spanish, Italian
- Portuguese (BR), Dutch, Polish, Swedish, Russian
- Chinese (Simplified), Japanese, Korean, Arabic

## ğŸ“± Browser Compatibility

- âœ… Chrome 80+
- âœ… Firefox 75+
- âœ… Safari 13+
- âœ… Edge 80+

**Required APIs:**
- MediaRecorder API (for recording)
- Web Audio API (for audio visualization)
- Fetch API (for OpenAI integration)
- IndexedDB (for audio archive)

## ğŸ”’ Privacy & Security

- **Local Processing**: All audio processing happens client-side
- **Secure Storage**: API keys are stored locally in encrypted format
- **No Data Collection**: No user data is sent to third parties except OpenAI
- **HTTPS Required**: Use HTTPS in production for microphone access

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Workflow

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run tests and linting
5. Commit your changes (`git commit -m 'Add amazing feature'`)
6. Push to the branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

## ğŸ—ºï¸ Roadmap

See our [detailed roadmap](ROADMAP.md) for upcoming features and improvements.

### Upcoming Features
- ğŸ“± Progressive Web App (PWA) support
- ğŸ”— Integration with cloud storage services
- ğŸ“Š Advanced analytics and insights
- ğŸ›ï¸ Audio editing capabilities
- ğŸ”Œ Plugin system for extensibility

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“¦ Versioning

We use [Semantic Versioning](https://semver.org/) for versioning. For the versions available, see the [VERSION.md](VERSION.md) file and the [tags on this repository](https://github.com/ChrisDCG/Lokal_neu/tags).

**Current Version:** v1.0.0

### Version History
- **v1.0.0** - Initial release with complete repository restructure and professional development setup

## ğŸ™ Acknowledgments

- [OpenAI](https://openai.com/) for providing the Whisper and GPT APIs
- [Tailwind CSS](https://tailwindcss.com/) for the utility-first CSS framework
- [Font Awesome](https://fontawesome.com/) for the beautiful icons
- The open-source community for inspiration and feedback

## ğŸ“ Support

- ğŸ› **Bug Reports**: [Create an issue](https://github.com/ChrisDCG/Lokal_neu/issues)
- ğŸ’¡ **Feature Requests**: [Start a discussion](https://github.com/ChrisDCG/Lokal_neu/discussions)
- ğŸ“§ **Direct Contact**: Open an issue for support questions

---

<div align="center">

**Made with â¤ï¸ by the Audio Suite Pro team**

[â¬† Back to top](#audio-suite-pro)

</div>
